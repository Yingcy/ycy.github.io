# 高斯分布的最大拟然估计(人工智能课程)

数学基础
$$
\frac{\part}{\part x}(A^{-1})=-A^{-1}\frac{\part A}{\part x}(A^{-1}) \tag1
$$

$$
\frac{\partial}{\partial A}Tr(AB)=B^T,\quad
\frac{\partial}{\partial A}Tr(A^TB)=B,\quad
\frac{\partial}{\partial A}Tr(A)=I \tag2
$$

$$
\frac{\partial}{\partial A}\ln |A|=(A^{-1})^T=A^{-T} \tag3
$$



给定一个数据集$X=(x^1,\cdots,x^n)^T$，其中观测${x_n}$假定是独立地从多元高斯分布中抽取的。我们可以使用最大拟然法估计分布的参数。对数拟然函数为
$$
\ln p(X|\vec{\mu},\Sigma)=-\frac{ND}{2}\ln (2\pi)-\frac{N}{2}\ln |\Sigma|-\frac{1}{2}\sum_{n=1}^{N}{(\vec{x_n}-\vec{\mu})^T\Sigma^{-1}(\vec{x_n}-\vec{\mu})} \tag 4
$$
该函数关于$\vec{\mu}$的导数为
$$
\frac{\partial}{\partial\vec{\mu}}\ln p(X|\vec\mu,\Sigma)=\sum_{n=1}^{N}{\Sigma^{-1}(\vec{x_n}-\vec\mu)} \tag5
$$
令这个导数为零，得到均值的最大拟然估计
$$
\vec\mu_{ML}=\frac{1}{N}\sum_{n=1}^{N}{\vec{x_n}} \tag6
$$
关于$\Sigma$的最大值为
$$
\Sigma_{ML}=\frac{1}{N}\sum_{n=1}^{N}{(\vec{x_n}-\vec\mu_{ML})(\vec{x_n}-\vec\mu_{ML})^T} \tag7
$$
最大拟然解的期望为
$$
E[\vec\mu_{ML}]=\vec\mu \tag8
$$

$$
E[\Sigma_{ML}]=\frac{N-1}{N}\Sigma \tag9
$$

###### 2.34 多元高斯分布的对数拟然函数对$\Sigma$进行求导

为了找到多元⾼斯分布的协⽅差矩阵的最⼤似然解，我们需要关于$\Sigma$最⼤化对数似然函数。注意，协⽅差矩阵⼀定是对称的、正定的。这里，我们忽略这些限制，直接进行最大化。使用附录C中的结论（C.21）、（C.26）和（C.28），证明最⼤化对数似然函数（2.118）的协⽅差矩阵$\Sigma$由样本协⽅差（2.122）给出。我们注意到最终求得的结果确实是对称的、正定的（假设样本协⽅差矩阵⾮奇异）。

即多元高斯分布的对数拟然函数对$\Sigma$进行求导
$$
\begin{aligned}
\frac{\partial}{\partial\Sigma}\ln p(X|\vec\mu,\Sigma)=&\frac{\partial}{\partial\Sigma}[-\frac{ND}{2}\ln (2\pi)]
-\frac{N}{2}\frac{\partial}{\partial\Sigma}\ln |\Sigma|\\
&-\frac{1}{2}\frac{\partial}{\partial\Sigma}\sum_{n=1}^{N}{(\vec{x_n}-\vec{\mu})^T\Sigma^{-1}(\vec{x_n}-\vec{\mu})}
\end{aligned} \tag{10}
$$
第一项常数对协方差矩阵求微分，为0。剩余两项求导可得。

###### 初代版本

$$
\begin{aligned}
\frac{\partial}{\partial\Sigma}\ln p(X|\vec\mu,\Sigma)&=-\frac{N}{2}(\Sigma^{-1})^T
-\frac{1}{2}\sum_{n=1}^{N}{\frac{\part}{\part{\Sigma}}(\vec{x_n}-\vec\mu)^T\Sigma^{-1}(\vec{x_n}-\vec\mu)}\\
&=-\frac{N}{2}\Sigma^{-T}-\frac{1}{2}\sum_{n=1}^{N}{[-\Sigma^{-T}(\vec{x_n}-\vec\mu)^T(\vec{x_n}-\vec\mu)^T\Sigma^{-T}]}\\
&=-\frac{N}{2}\Sigma^{-T}+\frac{1}{2}\sum_{n=1}^{N}{[-\Sigma^{-T}(\vec{x_n}-\vec\mu)^T(\vec{x_n}-\vec\mu)^T\Sigma^{-T}]}
\end{aligned} \tag{11}
$$

以上变形存在一定错误，应当是第三项求导过程错误。

###### 答案做法

对于第三项，设置
$$
S=\frac{1}{N}\sum_{n=1}^{N}{(\vec{x_n}-\vec\mu)(\vec{x_n}-\vec\mu)^T} \tag{12}
$$
第三项待微分部分变形得到
$$
\sum_{n=1}^{N}{(\vec{x_n}-\vec\mu)^T\Sigma^{-1}(\vec{x_n}-\vec\mu)}=N\cdot Tr[\Sigma^{-1}S]\tag{13}
$$
求微分，$\Sigma_{ij}$为矩阵$\Sigma$中的向量
$$
\begin{aligned}
\frac{\partial}{\partial\Sigma_{ij}}\sum_{n=1}^{N}{(\vec{x_n}-\vec{\mu})^T\Sigma^{-1}(\vec{x_n}-\vec{\mu})}
&=N\frac{\partial}{\partial\Sigma_{ij}}Tr[\Sigma^{-1}S]\\
&=N\cdot Tr[\frac{\partial}{\partial\Sigma_{ij}}\Sigma^{-1}S]\\
&=-N\cdot Tr[\Sigma^{-1}\frac{\partial\Sigma}{\partial\Sigma_{ij}}\Sigma^{-1}S]\\
&=-N\cdot Tr[\frac{\partial\Sigma}{\partial\Sigma_{ij}}\Sigma^{-1}S\Sigma^{-1}]\\

\end{aligned}\tag{14}
$$
对于向量$\Sigma_{ij}$来说，其他项均为0，仅剩对自身向量求导为1。进一步变形
$$
-N\cdot Tr[\frac{\partial\Sigma}{\partial\Sigma_{ij}}\Sigma^{-1}S\Sigma^{-1}]=-N(\Sigma^{-1}S\Sigma^{-1})_{ij}=-N(\Sigma^{-1}S\Sigma^{-1})\tag{15}
$$
第三项求微分最后结果为
$$
-\frac{1}{2}\frac{\partial}{\partial\Sigma}\sum_{n=1}^{N}{(\vec{x_n}-\vec{\mu})^T\Sigma^{-1}(\vec{x_n}-\vec{\mu})}=\frac{N}{2}(\Sigma^{-1}S\Sigma^{-1}) \tag{16}
$$
最后就微分结果应为
$$
\frac{\partial}{\partial\Sigma}\ln p(X|\vec\mu,\Sigma)=-\frac{N}{2}\Sigma^{-T}+\frac{N}{2}(\Sigma^{-1}S\Sigma^{-1}) \tag{17}
$$
令这个导数为零，得到
$$
\frac{N}{2}\Sigma^{-T}=\frac{N}{2}(\Sigma^{-1}S\Sigma^{-1})\tag{18}\\
$$

$$
\Sigma=S \tag{19}
$$

